---
title: "Vignette Title"
author: "Kristoffer Brix"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
\usepackage{amsmath}
\usepackage{bm}


## Weibull regression 

Let $X \sim W(a, \gamma)$, we say that $X$ is Weibull distributed with shape parameter $a > 0$ and scale parameter $\gamma > 0$. The distribution function is:

$$
F_X(x) = 1 - e^{- \left( \frac{x}{a} \right)^\gamma}, 
\qquad x > 0.
$$
Taking the derivative gives

$$
f_X(x)
= 
a^{- \gamma} \gamma x^{\gamma -1} e^{- a^{- \gamma} x^\gamma}
=
\left( \frac{x}{a} \right)^\gamma \gamma x^{-1} e^{- \left( \frac{x}{a} \right)^\gamma},
\qquad x > 0,
$$
and the expectation is 

$$
EX = a \Gamma \left( 1 + \frac{1}{\gamma} \right).
$$

Let $\boldsymbol X = (X_1, \dots, X_n) \sim W(\boldsymbol a, \gamma)$. By this, we mean that the components of the random vector $\boldsymbol X$ are Weibul distributed, $X_i \sim W(a_i, \gamma)$, where $a_i > 0$ and $\gamma > 0$ for $i = 1, \dots, n$. We use the natural regression $\boldsymbol a = e^{\boldsymbol{Z \beta}}$, where $\boldsymbol Z$ is a $n \times p$ design/model matrix and $\boldsymbol \beta$ is a $p$-dimensional column vector. Component-wise, we get $a_i = e^{\boldsymbol{z_i \beta}}$, using 

$$
\boldsymbol Z
 =
 \begin{pmatrix}
  z_{11} & z_{12} & \cdots & z_{1p} \\
  z_{21} & z_{22} & \cdots & z_{2p} \\
  \vdots & \vdots & \ddots & \vdots \\
  z_{n1} & z_{n1} & \cdots & z_{np}
 \end{pmatrix}
 =
 \begin{pmatrix}
  \boldsymbol z_1 \\ 
  \boldsymbol z_2 \\
  \vdots \\ 
  \boldsymbol z_n
 \end{pmatrix},
$$

where $\boldsymbol z_i = (z_{i1}, \dots, z_{ip})$ are $p$-dimensional row vectors for $i = 1, \dots, n$.

The log-likelihood is then

\begin{align}
l(\boldsymbol \beta, b; \boldsymbol x)
&=
n \log \gamma
-
\sum_{i = 1}^n
\left(
\gamma \: \log a_i - (\gamma - 1) \log x_i + a_i^{-\gamma} x_i^\gamma 
\right)
\\
&= 
n \log \gamma
-
\sum_{i = 1}^n
\left( 
\gamma \: \boldsymbol{z_i \beta} - (\gamma-1) \log x_i 
+ e^{-\gamma \: \boldsymbol{z_i \beta}} x_i^\gamma
\right).
\end{align}

With the inclusion of a deductible $d_i > 0$ for each claim $x_i > 0$, we instead get
$$
l(\boldsymbol \beta, b; \boldsymbol x)
=
n \log \gamma
-
\sum_{i = 1}^n
\left( 
\gamma \: \boldsymbol{z_i \beta} - (\gamma-1) \log x_i 
+ e^{-\gamma \: \boldsymbol{z_i \beta}} 
\left( x_i^\gamma - d_i^\gamma \right)
\right).
$$
A natural reparametrization is to let $\boldsymbol \alpha = \gamma \boldsymbol \beta$, such that...

## Zero-inflated Poisson regression

Let $M$ be a counting distribution on $\mathbb N_0$ and let $I$ be Bernoulli distributed, $I \sim \text{Bernoulli}(1-p)$, $p \in (0,1)$, with $I$ independent of $M$, then define $N = I \cdot M$.

The distribution of $N$ is 

\begin{align*}
P(N = 0) &= P(I = 0) + P(I = 1, \: M = 0) = p + (1 - p) \cdot P(M = 0), \\
P(N = n) &= P(I = 1, \: M = n) = (1 - p) \cdot P(M = n), \qquad n \in \mathbb N.
\end{align*}

Since it always holds that $P(N = 0) > P(M = 0)$, we call $N$ a zero-inflated version of $M$. When $M$ is Poisson distributed, i.e. $M \sim \text{Poisson}(\lambda)$, $\lambda > 0$, we say that $N$ is zero-inflated Poisson distributed and write $N \sim \text{ZIP}(\lambda, p)$, in this case, we have

\begin{align*}
P(N = 0) &=  p + (1 - p) \cdot e^{-\lambda}, \\
P(N = n) &= (1 - p) \cdot \frac{\lambda^n}{n!} e^{-\lambda}, \qquad n \in \mathbb N.
\end{align*}

### Proposition
Let $N^* \sim \text{Poisson}(\lambda)$, $\lambda > 0$ and let $N^* = N + M$, where

$$
N = \sum_{i = 1}^{N^*} I_i
\qquad \text{and} \qquad M = \sum_{i = 1}^{N^*} (1 - I_i), 
$$

and the $I_i$ are i.i.d. Bernoulli distributed with success parameter $q \in (0,1)$. Then

$$
N \sim \text{Poisson}\left( q \cdot \lambda \right) 
\: {\perp\!\!\!\!\perp} \: 
M \sim \text{Poisson}\left( (1-q) \cdot \lambda \right).
$$
*Proof*. Note that $(N \mid N^* = n^*) \sim \text{Bin}(n^*, q)$, therefore, with $n + m = n^*$, we have

\begin{align*}
 P(N = n, \: M = m)
 &= P(N = n, \: N^* = n + m) \\
 &= P(N = n \mid N^* = n + m) P(N^* = n + m) \\
 &= 
 \frac{(n + m)!}{n! m!} q^n (1-q)^m
 \frac{\lambda^{n+m}}{(n+m)!} e^{-\lambda} \\
 &=
 \frac{(q\lambda)^n}{n!} e^{-q\lambda}
 \frac{((1-q) \lambda)^m}{m!} e^{-(1-q) \lambda} \\
 &=
 P(N = n) P(M = m).
 
\end{align*}

Which proves the result.

We say that a family of distributions $\mathscr F$ is closed under *thinning* if whenever $N^*$ is in $\mathscr F$, then any *thinned* version $N$ (as in the above) is also in $\mathscr F$. The above results show that the Poisson distribution is closed under thinning. 

It also holds that the zero-inflated Poisson distribution is closed under thinning. Let $N^* = I \cdot M$ and set

$$
N_1 = \sum_{i = 1}^{N^*} I_i,
\quad
M = \sum_{i = 1}^{M^*} I_i
\qquad \text{and} \quad 
N_2 = I \cdot M,
$$
where the $I_i$ are i.i.d. Bernoulli distributed with success parameter $q \in (0,1)$, independent of $M^*$ and $I_i$. It is easy to see, say, using characteristic functions, that $N_1$ and $N_2$ have the same distribution.

Thus, a zero-inflated thinned random variable $N_2$ has the same distribution as the thinned version of the zero-inflated original random variable $N_1$. In particular, we have that
$$
N^âˆ— \sim \text{ZIP}(\lambda, \: p)
\quad \Longrightarrow \quad 
N_1 \sim \text{ZIP}(q \cdot \lambda, \: p),
$$
so the zero-inflated Poisson distribution is also closed under thinning. This actually holds for all $q > 0$ using a Poisson process argument. 

\ 
&nbsp;




Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
